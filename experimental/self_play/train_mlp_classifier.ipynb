{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb321fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-saved Parquet datasets...\n",
      "Fitting logistic regression...\n",
      "Logistic Regression - Validation accuracy: 0.6026Fitting MLPClassifier with hidden layer size 3...\n",
      "Iteration 1, loss = 0.81917053\n",
      "Validation score: 0.590100\n",
      "Iteration 2, loss = 0.79143769\n",
      "Validation score: 0.594250\n",
      "Iteration 3, loss = 0.78888577\n",
      "Validation score: 0.593360\n",
      "Iteration 4, loss = 0.78813630\n",
      "Validation score: 0.598980\n",
      "Iteration 5, loss = 0.78754914\n",
      "Validation score: 0.598370\n",
      "Iteration 6, loss = 0.78703403\n",
      "Validation score: 0.596350\n",
      "Iteration 7, loss = 0.78683811\n",
      "Validation score: 0.598680\n",
      "Iteration 8, loss = 0.78654581\n",
      "Validation score: 0.598910\n",
      "Iteration 9, loss = 0.78630394\n",
      "Validation score: 0.598800\n",
      "Iteration 10, loss = 0.78603274\n",
      "Validation score: 0.599700\n",
      "Iteration 11, loss = 0.78596365\n",
      "Validation score: 0.596700\n",
      "Iteration 12, loss = 0.78583187\n",
      "Validation score: 0.600950\n",
      "Iteration 13, loss = 0.78561676\n",
      "Validation score: 0.600340\n",
      "Iteration 14, loss = 0.78555179\n",
      "Validation score: 0.601340\n",
      "Iteration 15, loss = 0.78538591\n",
      "Validation score: 0.597790\n",
      "Iteration 16, loss = 0.78526813\n",
      "Validation score: 0.601220\n",
      "Iteration 17, loss = 0.78520477\n",
      "Validation score: 0.599930\n",
      "Iteration 18, loss = 0.78511828\n",
      "Validation score: 0.599200\n",
      "Iteration 19, loss = 0.78495741\n",
      "Validation score: 0.596180\n",
      "Iteration 20, loss = 0.78487509\n",
      "Validation score: 0.599840\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=3) - Validation accuracy: 0.6015\n",
      "Fitting MLPClassifier with hidden layer size 4...\n",
      "Iteration 1, loss = 0.81515944\n",
      "Validation score: 0.578950\n",
      "Iteration 2, loss = 0.79219633\n",
      "Validation score: 0.594390\n",
      "Iteration 3, loss = 0.78910643\n",
      "Validation score: 0.596980\n",
      "Iteration 4, loss = 0.78781396\n",
      "Validation score: 0.596910\n",
      "Iteration 5, loss = 0.78715515\n",
      "Validation score: 0.597180\n",
      "Iteration 6, loss = 0.78637981\n",
      "Validation score: 0.597000\n",
      "Iteration 7, loss = 0.78584617\n",
      "Validation score: 0.598380\n",
      "Iteration 8, loss = 0.78542286\n",
      "Validation score: 0.597100\n",
      "Iteration 9, loss = 0.78498280\n",
      "Validation score: 0.599000\n",
      "Iteration 10, loss = 0.78446877\n",
      "Validation score: 0.597770\n",
      "Iteration 11, loss = 0.78412384\n",
      "Validation score: 0.599080\n",
      "Iteration 12, loss = 0.78374207\n",
      "Validation score: 0.596820\n",
      "Iteration 13, loss = 0.78344089\n",
      "Validation score: 0.597850\n",
      "Iteration 14, loss = 0.78330201\n",
      "Validation score: 0.598850\n",
      "Iteration 15, loss = 0.78312320\n",
      "Validation score: 0.598030\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=4) - Validation accuracy: 0.5999\n",
      "Fitting MLPClassifier with hidden layer size 5...\n",
      "Iteration 1, loss = 0.81893921\n",
      "Validation score: 0.593720\n",
      "Iteration 2, loss = 0.79122686\n",
      "Validation score: 0.598300\n",
      "Iteration 3, loss = 0.78881162\n",
      "Validation score: 0.598100\n",
      "Iteration 4, loss = 0.78766018\n",
      "Validation score: 0.597810\n",
      "Iteration 5, loss = 0.78689575\n",
      "Validation score: 0.598400\n",
      "Iteration 6, loss = 0.78637683\n",
      "Validation score: 0.599440\n",
      "Iteration 7, loss = 0.78585607\n",
      "Validation score: 0.600010\n",
      "Iteration 8, loss = 0.78543609\n",
      "Validation score: 0.595720\n",
      "Iteration 9, loss = 0.78511560\n",
      "Validation score: 0.598920\n",
      "Iteration 10, loss = 0.78470421\n",
      "Validation score: 0.599750\n",
      "Iteration 11, loss = 0.78459430\n",
      "Validation score: 0.601220\n",
      "Iteration 12, loss = 0.78431153\n",
      "Validation score: 0.599710\n",
      "Iteration 13, loss = 0.78411597\n",
      "Validation score: 0.602890\n",
      "Iteration 14, loss = 0.78382611\n",
      "Validation score: 0.600710\n",
      "Iteration 15, loss = 0.78372097\n",
      "Validation score: 0.601140\n",
      "Iteration 16, loss = 0.78352678\n",
      "Validation score: 0.598660\n",
      "Iteration 17, loss = 0.78330123\n",
      "Validation score: 0.602000\n",
      "Iteration 18, loss = 0.78324825\n",
      "Validation score: 0.601060\n",
      "Iteration 19, loss = 0.78313285\n",
      "Validation score: 0.599180\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=5) - Validation accuracy: 0.6016\n",
      "Fitting MLPClassifier with hidden layer size 6...\n",
      "Iteration 1, loss = 0.81213582\n",
      "Validation score: 0.592350\n",
      "Iteration 2, loss = 0.79073662\n",
      "Validation score: 0.593180\n",
      "Iteration 3, loss = 0.78835648\n",
      "Validation score: 0.596410\n",
      "Iteration 4, loss = 0.78699720\n",
      "Validation score: 0.597910\n",
      "Iteration 5, loss = 0.78609502\n",
      "Validation score: 0.596580\n",
      "Iteration 6, loss = 0.78521019\n",
      "Validation score: 0.597490\n",
      "Iteration 7, loss = 0.78453887\n",
      "Validation score: 0.598660\n",
      "Iteration 8, loss = 0.78401130\n",
      "Validation score: 0.597560\n",
      "Iteration 9, loss = 0.78351617\n",
      "Validation score: 0.597870\n",
      "Iteration 10, loss = 0.78305703\n",
      "Validation score: 0.597560\n",
      "Iteration 11, loss = 0.78280652\n",
      "Validation score: 0.594830\n",
      "Iteration 12, loss = 0.78242362\n",
      "Validation score: 0.598100\n",
      "Iteration 13, loss = 0.78216839\n",
      "Validation score: 0.598370\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=6) - Validation accuracy: 0.6008\n",
      "Fitting MLPClassifier with hidden layer size 7...\n",
      "Iteration 1, loss = 0.80858201\n",
      "Validation score: 0.592810\n",
      "Iteration 2, loss = 0.79031116\n",
      "Validation score: 0.595160\n",
      "Iteration 3, loss = 0.78774756\n",
      "Validation score: 0.597430\n",
      "Iteration 4, loss = 0.78630298\n",
      "Validation score: 0.598060\n",
      "Iteration 5, loss = 0.78521162\n",
      "Validation score: 0.599020\n",
      "Iteration 6, loss = 0.78429681\n",
      "Validation score: 0.595910\n",
      "Iteration 7, loss = 0.78375912\n",
      "Validation score: 0.598180\n",
      "Iteration 8, loss = 0.78321266\n",
      "Validation score: 0.600090\n",
      "Iteration 9, loss = 0.78269571\n",
      "Validation score: 0.597340\n",
      "Iteration 10, loss = 0.78226030\n",
      "Validation score: 0.597400\n",
      "Iteration 11, loss = 0.78188300\n",
      "Validation score: 0.598470\n",
      "Iteration 12, loss = 0.78146762\n",
      "Validation score: 0.598470\n",
      "Iteration 13, loss = 0.78112638\n",
      "Validation score: 0.601150\n",
      "Iteration 14, loss = 0.78084856\n",
      "Validation score: 0.598450\n",
      "Iteration 15, loss = 0.78079921\n",
      "Validation score: 0.600280\n",
      "Iteration 16, loss = 0.78046668\n",
      "Validation score: 0.599340\n",
      "Iteration 17, loss = 0.78022623\n",
      "Validation score: 0.600830\n",
      "Iteration 18, loss = 0.78006643\n",
      "Validation score: 0.599120\n",
      "Iteration 19, loss = 0.77991146\n",
      "Validation score: 0.598470\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=7) - Validation accuracy: 0.6014\n",
      "Fitting MLPClassifier with hidden layer size 8...\n",
      "Iteration 1, loss = 0.81143749\n",
      "Validation score: 0.593330\n",
      "Iteration 2, loss = 0.79078269\n",
      "Validation score: 0.595690\n",
      "Iteration 3, loss = 0.78808081\n",
      "Validation score: 0.597940\n",
      "Iteration 4, loss = 0.78662145\n",
      "Validation score: 0.598490\n",
      "Iteration 5, loss = 0.78555924\n",
      "Validation score: 0.595990\n",
      "Iteration 6, loss = 0.78481936\n",
      "Validation score: 0.599270\n",
      "Iteration 7, loss = 0.78413951\n",
      "Validation score: 0.599450\n",
      "Iteration 8, loss = 0.78360736\n",
      "Validation score: 0.598480\n",
      "Iteration 9, loss = 0.78317082\n",
      "Validation score: 0.597600\n",
      "Iteration 10, loss = 0.78279680\n",
      "Validation score: 0.598870\n",
      "Iteration 11, loss = 0.78237355\n",
      "Validation score: 0.599530\n",
      "Iteration 12, loss = 0.78214926\n",
      "Validation score: 0.600420\n",
      "Iteration 13, loss = 0.78185320\n",
      "Validation score: 0.597140\n",
      "Iteration 14, loss = 0.78158259\n",
      "Validation score: 0.600620\n",
      "Iteration 15, loss = 0.78125006\n",
      "Validation score: 0.600020\n",
      "Iteration 16, loss = 0.78092414\n",
      "Validation score: 0.600770\n",
      "Iteration 17, loss = 0.78075182\n",
      "Validation score: 0.600080\n",
      "Iteration 18, loss = 0.78051436\n",
      "Validation score: 0.600780\n",
      "Iteration 19, loss = 0.78018373\n",
      "Validation score: 0.601870\n",
      "Iteration 20, loss = 0.77996033\n",
      "Validation score: 0.600990\n",
      "Iteration 21, loss = 0.77990741\n",
      "Validation score: 0.601860\n",
      "Iteration 22, loss = 0.77953613\n",
      "Validation score: 0.600270\n",
      "Iteration 23, loss = 0.77953708\n",
      "Validation score: 0.602820\n",
      "Iteration 24, loss = 0.77934015\n",
      "Validation score: 0.600560\n",
      "Iteration 25, loss = 0.77923244\n",
      "Validation score: 0.598750\n",
      "Iteration 26, loss = 0.77900749\n",
      "Validation score: 0.599890\n",
      "Iteration 27, loss = 0.77893591\n",
      "Validation score: 0.601100\n",
      "Iteration 28, loss = 0.77880776\n",
      "Validation score: 0.600850\n",
      "Iteration 29, loss = 0.77867079\n",
      "Validation score: 0.602910\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=8) - Validation accuracy: 0.6027\n",
      "Fitting MLPClassifier with hidden layer size 9...\n",
      "Iteration 1, loss = 0.80877984\n",
      "Validation score: 0.594300\n",
      "Iteration 2, loss = 0.79007792\n",
      "Validation score: 0.594440\n",
      "Iteration 3, loss = 0.78749442\n",
      "Validation score: 0.599500\n",
      "Iteration 4, loss = 0.78583258\n",
      "Validation score: 0.598920\n",
      "Iteration 5, loss = 0.78471988\n",
      "Validation score: 0.597970\n",
      "Iteration 6, loss = 0.78389895\n",
      "Validation score: 0.598750\n",
      "Iteration 7, loss = 0.78321779\n",
      "Validation score: 0.601930\n",
      "Iteration 8, loss = 0.78270751\n",
      "Validation score: 0.597510\n",
      "Iteration 9, loss = 0.78217977\n",
      "Validation score: 0.600540\n",
      "Iteration 10, loss = 0.78181922\n",
      "Validation score: 0.601740\n",
      "Iteration 11, loss = 0.78145570\n",
      "Validation score: 0.601800\n",
      "Iteration 12, loss = 0.78100544\n",
      "Validation score: 0.600740\n",
      "Iteration 13, loss = 0.78066164\n",
      "Validation score: 0.602850\n",
      "Iteration 14, loss = 0.78030509\n",
      "Validation score: 0.602940\n",
      "Iteration 15, loss = 0.78004873\n",
      "Validation score: 0.601180\n",
      "Iteration 16, loss = 0.77989602\n",
      "Validation score: 0.601290\n",
      "Iteration 17, loss = 0.77952075\n",
      "Validation score: 0.602060\n",
      "Iteration 18, loss = 0.77931178\n",
      "Validation score: 0.600700\n",
      "Iteration 19, loss = 0.77895558\n",
      "Validation score: 0.602960\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=9) - Validation accuracy: 0.6023\n",
      "Fitting MLPClassifier with hidden layer size 10...\n",
      "Iteration 1, loss = 0.80620569\n",
      "Validation score: 0.594970\n",
      "Iteration 2, loss = 0.78931367\n",
      "Validation score: 0.596780\n",
      "Iteration 3, loss = 0.78657067\n",
      "Validation score: 0.596620\n",
      "Iteration 4, loss = 0.78509235\n",
      "Validation score: 0.597370\n",
      "Iteration 5, loss = 0.78376627\n",
      "Validation score: 0.597990\n",
      "Iteration 6, loss = 0.78291631\n",
      "Validation score: 0.597530\n",
      "Iteration 7, loss = 0.78208935\n",
      "Validation score: 0.599220\n",
      "Iteration 8, loss = 0.78145075\n",
      "Validation score: 0.598000\n",
      "Iteration 9, loss = 0.78094709\n",
      "Validation score: 0.599170\n",
      "Iteration 10, loss = 0.78043383\n",
      "Validation score: 0.599340\n",
      "Iteration 11, loss = 0.77993029\n",
      "Validation score: 0.597670\n",
      "Iteration 12, loss = 0.77948207\n",
      "Validation score: 0.597060\n",
      "Iteration 13, loss = 0.77910298\n",
      "Validation score: 0.599310\n",
      "Iteration 14, loss = 0.77863097\n",
      "Validation score: 0.599160\n",
      "Iteration 15, loss = 0.77827668\n",
      "Validation score: 0.600170\n",
      "Iteration 16, loss = 0.77795076\n",
      "Validation score: 0.599580\n",
      "Iteration 17, loss = 0.77767330\n",
      "Validation score: 0.597030\n",
      "Iteration 18, loss = 0.77740121\n",
      "Validation score: 0.597990\n",
      "Iteration 19, loss = 0.77720827\n",
      "Validation score: 0.598180\n",
      "Iteration 20, loss = 0.77692533\n",
      "Validation score: 0.599060\n",
      "Iteration 21, loss = 0.77673507\n",
      "Validation score: 0.599560\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=10) - Validation accuracy: 0.6030\n",
      "Fitting MLPClassifier with hidden layer size 11...\n",
      "Iteration 1, loss = 0.80516428\n",
      "Validation score: 0.589510\n",
      "Iteration 2, loss = 0.78864861\n",
      "Validation score: 0.595400\n",
      "Iteration 3, loss = 0.78575784\n",
      "Validation score: 0.598770\n",
      "Iteration 4, loss = 0.78414726\n",
      "Validation score: 0.599320\n",
      "Iteration 5, loss = 0.78287220\n",
      "Validation score: 0.599170\n",
      "Iteration 6, loss = 0.78195924\n",
      "Validation score: 0.600140\n",
      "Iteration 7, loss = 0.78127539\n",
      "Validation score: 0.600980\n",
      "Iteration 8, loss = 0.78054786\n",
      "Validation score: 0.599590\n",
      "Iteration 9, loss = 0.77994120\n",
      "Validation score: 0.601460\n",
      "Iteration 10, loss = 0.77938819\n",
      "Validation score: 0.600700\n",
      "Iteration 11, loss = 0.77888352\n",
      "Validation score: 0.600140\n",
      "Iteration 12, loss = 0.77856374\n",
      "Validation score: 0.600630\n",
      "Iteration 13, loss = 0.77816272\n",
      "Validation score: 0.600140\n",
      "Iteration 14, loss = 0.77773929\n",
      "Validation score: 0.602430\n",
      "Iteration 15, loss = 0.77746570\n",
      "Validation score: 0.601790\n",
      "Iteration 16, loss = 0.77719742\n",
      "Validation score: 0.602040\n",
      "Iteration 17, loss = 0.77689749\n",
      "Validation score: 0.600990\n",
      "Iteration 18, loss = 0.77674317\n",
      "Validation score: 0.599830\n",
      "Iteration 19, loss = 0.77647537\n",
      "Validation score: 0.601420\n",
      "Iteration 20, loss = 0.77632791\n",
      "Validation score: 0.599530\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=11) - Validation accuracy: 0.6022\n",
      "Fitting MLPClassifier with hidden layer size 12...\n",
      "Iteration 1, loss = 0.80814534\n",
      "Validation score: 0.593850\n",
      "Iteration 2, loss = 0.79011172\n",
      "Validation score: 0.594520\n",
      "Iteration 3, loss = 0.78735840\n",
      "Validation score: 0.593900\n",
      "Iteration 4, loss = 0.78548825\n",
      "Validation score: 0.598090\n",
      "Iteration 5, loss = 0.78445429\n",
      "Validation score: 0.598800\n",
      "Iteration 6, loss = 0.78343433\n",
      "Validation score: 0.597560\n",
      "Iteration 7, loss = 0.78275543\n",
      "Validation score: 0.599080\n",
      "Iteration 8, loss = 0.78204393\n",
      "Validation score: 0.599180\n",
      "Iteration 9, loss = 0.78142822\n",
      "Validation score: 0.601560\n",
      "Iteration 10, loss = 0.78075850\n",
      "Validation score: 0.600260\n",
      "Iteration 11, loss = 0.78017634\n",
      "Validation score: 0.601110\n",
      "Iteration 12, loss = 0.77975607\n",
      "Validation score: 0.601160\n",
      "Iteration 13, loss = 0.77927589\n",
      "Validation score: 0.601880\n",
      "Iteration 14, loss = 0.77896869\n",
      "Validation score: 0.601260\n",
      "Iteration 15, loss = 0.77848428\n",
      "Validation score: 0.601410\n",
      "Iteration 16, loss = 0.77812839\n",
      "Validation score: 0.600750\n",
      "Iteration 17, loss = 0.77765322\n",
      "Validation score: 0.601460\n",
      "Iteration 18, loss = 0.77727276\n",
      "Validation score: 0.599620\n",
      "Iteration 19, loss = 0.77698660\n",
      "Validation score: 0.602120\n",
      "Iteration 20, loss = 0.77668041\n",
      "Validation score: 0.599410\n",
      "Iteration 21, loss = 0.77626765\n",
      "Validation score: 0.601950\n",
      "Iteration 22, loss = 0.77606171\n",
      "Validation score: 0.600940\n",
      "Iteration 23, loss = 0.77580428\n",
      "Validation score: 0.601570\n",
      "Iteration 24, loss = 0.77560127\n",
      "Validation score: 0.602220\n",
      "Iteration 25, loss = 0.77537560\n",
      "Validation score: 0.601150\n",
      "Iteration 26, loss = 0.77517903\n",
      "Validation score: 0.600520\n",
      "Iteration 27, loss = 0.77496517\n",
      "Validation score: 0.601520\n",
      "Iteration 28, loss = 0.77490300\n",
      "Validation score: 0.601080\n",
      "Iteration 29, loss = 0.77469993\n",
      "Validation score: 0.601720\n",
      "Iteration 30, loss = 0.77450371\n",
      "Validation score: 0.601620\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=12) - Validation accuracy: 0.6034\n",
      "Fitting MLPClassifier with hidden layer size 13...\n",
      "Iteration 1, loss = 0.80635405\n",
      "Validation score: 0.594330\n",
      "Iteration 2, loss = 0.78828001\n",
      "Validation score: 0.596230\n",
      "Iteration 3, loss = 0.78521299\n",
      "Validation score: 0.592970\n",
      "Iteration 4, loss = 0.78320855\n",
      "Validation score: 0.597910\n",
      "Iteration 5, loss = 0.78168654\n",
      "Validation score: 0.597130\n",
      "Iteration 6, loss = 0.78054577\n",
      "Validation score: 0.598400\n",
      "Iteration 7, loss = 0.77951735\n",
      "Validation score: 0.599610\n",
      "Iteration 8, loss = 0.77884120\n",
      "Validation score: 0.599080\n",
      "Iteration 9, loss = 0.77807522\n",
      "Validation score: 0.600540\n",
      "Iteration 10, loss = 0.77747720\n",
      "Validation score: 0.599290\n",
      "Iteration 11, loss = 0.77696449\n",
      "Validation score: 0.596860\n",
      "Iteration 12, loss = 0.77652776\n",
      "Validation score: 0.598260\n",
      "Iteration 13, loss = 0.77603436\n",
      "Validation score: 0.599510\n",
      "Iteration 14, loss = 0.77567536\n",
      "Validation score: 0.599960\n",
      "Iteration 15, loss = 0.77532244\n",
      "Validation score: 0.599630\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=13) - Validation accuracy: 0.6009\n",
      "Fitting MLPClassifier with hidden layer size 14...\n",
      "Iteration 1, loss = 0.80710983\n",
      "Validation score: 0.594710\n",
      "Iteration 2, loss = 0.78899097\n",
      "Validation score: 0.594340\n",
      "Iteration 3, loss = 0.78595430\n",
      "Validation score: 0.596760\n",
      "Iteration 4, loss = 0.78393447\n",
      "Validation score: 0.595730\n",
      "Iteration 5, loss = 0.78247875\n",
      "Validation score: 0.595340\n",
      "Iteration 6, loss = 0.78127354\n",
      "Validation score: 0.599050\n",
      "Iteration 7, loss = 0.78025359\n",
      "Validation score: 0.599380\n",
      "Iteration 8, loss = 0.77937907\n",
      "Validation score: 0.599440\n",
      "Iteration 9, loss = 0.77874523\n",
      "Validation score: 0.600740\n",
      "Iteration 10, loss = 0.77808791\n",
      "Validation score: 0.600220\n",
      "Iteration 11, loss = 0.77754539\n",
      "Validation score: 0.600030\n",
      "Iteration 12, loss = 0.77701360\n",
      "Validation score: 0.599680\n",
      "Iteration 13, loss = 0.77634215\n",
      "Validation score: 0.598820\n",
      "Iteration 14, loss = 0.77590090\n",
      "Validation score: 0.600660\n",
      "Iteration 15, loss = 0.77541476\n",
      "Validation score: 0.598610\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=14) - Validation accuracy: 0.6011\n",
      "Fitting MLPClassifier with hidden layer size 15...\n",
      "Iteration 1, loss = 0.80667162\n",
      "Validation score: 0.591260\n",
      "Iteration 2, loss = 0.78965658\n",
      "Validation score: 0.596140\n",
      "Iteration 3, loss = 0.78678167\n",
      "Validation score: 0.597540\n",
      "Iteration 4, loss = 0.78463888\n",
      "Validation score: 0.598940\n",
      "Iteration 5, loss = 0.78307569\n",
      "Validation score: 0.593310\n",
      "Iteration 6, loss = 0.78184211\n",
      "Validation score: 0.600180\n",
      "Iteration 7, loss = 0.78092068\n",
      "Validation score: 0.599480\n",
      "Iteration 8, loss = 0.78013855\n",
      "Validation score: 0.600380\n",
      "Iteration 9, loss = 0.77944380\n",
      "Validation score: 0.600760\n",
      "Iteration 10, loss = 0.77885431\n",
      "Validation score: 0.598500\n",
      "Iteration 11, loss = 0.77815431\n",
      "Validation score: 0.601590\n",
      "Iteration 12, loss = 0.77755439\n",
      "Validation score: 0.599820\n",
      "Iteration 13, loss = 0.77698535\n",
      "Validation score: 0.600750\n",
      "Iteration 14, loss = 0.77640152\n",
      "Validation score: 0.600520\n",
      "Iteration 15, loss = 0.77596438\n",
      "Validation score: 0.601680\n",
      "Iteration 16, loss = 0.77546120\n",
      "Validation score: 0.601440\n",
      "Iteration 17, loss = 0.77509880\n",
      "Validation score: 0.600120\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=15) - Validation accuracy: 0.6016\n",
      "Fitting MLPClassifier with hidden layer size 16...\n",
      "Iteration 1, loss = 0.80549628\n",
      "Validation score: 0.593530\n",
      "Iteration 2, loss = 0.78944749\n",
      "Validation score: 0.593440\n",
      "Iteration 3, loss = 0.78613883\n",
      "Validation score: 0.596900\n",
      "Iteration 4, loss = 0.78426015\n",
      "Validation score: 0.597510\n",
      "Iteration 5, loss = 0.78271431\n",
      "Validation score: 0.598440\n",
      "Iteration 6, loss = 0.78146803\n",
      "Validation score: 0.598150\n",
      "Iteration 7, loss = 0.78033131\n",
      "Validation score: 0.598180\n",
      "Iteration 8, loss = 0.77933460\n",
      "Validation score: 0.597240\n",
      "Iteration 9, loss = 0.77840680\n",
      "Validation score: 0.597220\n",
      "Iteration 10, loss = 0.77738386\n",
      "Validation score: 0.601290\n",
      "Iteration 11, loss = 0.77662539\n",
      "Validation score: 0.601130\n",
      "Iteration 12, loss = 0.77587789\n",
      "Validation score: 0.597010\n",
      "Iteration 13, loss = 0.77534747\n",
      "Validation score: 0.598390\n",
      "Iteration 14, loss = 0.77477765\n",
      "Validation score: 0.599360\n",
      "Iteration 15, loss = 0.77429801\n",
      "Validation score: 0.598590\n",
      "Iteration 16, loss = 0.77388901\n",
      "Validation score: 0.598160\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "MLPClassifier (hidden=16) - Validation accuracy: 0.6023\n",
      "Fitting MLPClassifier with hidden layer size 17...\n",
      "Iteration 1, loss = 0.80448282\n",
      "Validation score: 0.591040\n",
      "Iteration 2, loss = 0.78844672\n",
      "Validation score: 0.596880\n",
      "Iteration 3, loss = 0.78502655\n",
      "Validation score: 0.596130\n",
      "Iteration 4, loss = 0.78262770\n",
      "Validation score: 0.598060\n",
      "Iteration 5, loss = 0.78082716\n",
      "Validation score: 0.599530\n",
      "Iteration 6, loss = 0.77953124\n",
      "Validation score: 0.600830\n",
      "Iteration 7, loss = 0.77838284\n",
      "Validation score: 0.600900\n",
      "Iteration 8, loss = 0.77732593\n",
      "Validation score: 0.600970\n",
      "Iteration 9, loss = 0.77649826\n",
      "Validation score: 0.599830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\forbe\\.local\\share\\mamba\\envs\\chess\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier (hidden=17) - Validation accuracy: 0.6008\n",
      "Fitting MLPClassifier with hidden layer size 18...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# train_chess_lr.py\n",
    "\n",
    "import os\n",
    "\n",
    "import chess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# -------------------- Feature Extraction --------------------\n",
    "def extract_features(fen: str) -> np.ndarray:\n",
    "    board = chess.Board(fen)\n",
    "    arr = np.zeros(12 * 64, dtype=np.float32)\n",
    "    for sq, piece in board.piece_map().items():\n",
    "        ch = (piece.piece_type - 1) + (0 if piece.color == chess.WHITE else 6)\n",
    "        arr[ch * 64 + sq] = 1.0\n",
    "    n_pieces = len(board.piece_map())\n",
    "    factor1 = (n_pieces - 2) / 30\n",
    "    factor2 = (32 - n_pieces) / 30\n",
    "    return np.concatenate([arr * factor1, arr * factor2], axis=0)\n",
    "\n",
    "\n",
    "# -------------------- Dataset Processing --------------------\n",
    "def process_dataset(df: pd.DataFrame, size: int, desc: str):\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True).iloc[:size]\n",
    "    X = np.zeros((len(df), 2 * 12 * 64), dtype=np.float32)\n",
    "    y = df[\"value\"].values.astype(np.float32)\n",
    "    for i, fen in tqdm(enumerate(df[\"FEN\"]), total=len(df), desc=f\"Featurizing {desc}\"):\n",
    "        X[i] = extract_features(fen)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# -------------------- Load, Split, Save (using Parquet) --------------------\n",
    "def load_split_save(\n",
    "    train_csv: str, val_csv: str, train_size: int = 1_000_000, val_size: int = 100_000\n",
    "):\n",
    "    # Check for existing Parquet files\n",
    "    if (\n",
    "        os.path.exists(\"X_train.parquet\")\n",
    "        and os.path.exists(\"y_train.parquet\")\n",
    "        and os.path.exists(\"X_val.parquet\")\n",
    "        and os.path.exists(\"y_val.parquet\")\n",
    "    ):\n",
    "        print(\"Loading pre-saved Parquet datasets...\")\n",
    "        X_train = pd.read_parquet(\"X_train.parquet\").values\n",
    "        y_train = pd.read_parquet(\"y_train.parquet\")[\"value\"].values\n",
    "        X_val = pd.read_parquet(\"X_val.parquet\").values\n",
    "        y_val = pd.read_parquet(\"y_val.parquet\")[\"value\"].values\n",
    "        return X_train, y_train, X_val, y_val\n",
    "\n",
    "    # Read CSVs if Parquet not found\n",
    "    df_train = pd.read_csv(train_csv)\n",
    "    df_val = pd.read_csv(val_csv)\n",
    "\n",
    "    # Process datasets\n",
    "    X_train, y_train = process_dataset(df_train, train_size, \"train\")\n",
    "    X_val, y_val = process_dataset(df_val, val_size, \"val\")\n",
    "\n",
    "    # Save to Parquet\n",
    "    pd.DataFrame(X_train).to_parquet(\"X_train.parquet\", index=False)\n",
    "    pd.DataFrame({\"value\": y_train}).to_parquet(\"y_train.parquet\", index=False)\n",
    "    pd.DataFrame(X_val).to_parquet(\"X_val.parquet\", index=False)\n",
    "    pd.DataFrame({\"value\": y_val}).to_parquet(\"y_val.parquet\", index=False)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "# -------------------- Train Logistic Regression --------------------\n",
    "def train_logistic_regression(\n",
    "    X_train: np.ndarray, y_train: np.ndarray\n",
    ") -> LogisticRegression:\n",
    "    print(\"Fitting logistic regression...\")\n",
    "    lr = LogisticRegression(max_iter=1000, verbose=1)\n",
    "    lr.fit(X_train, y_train)\n",
    "    return lr\n",
    "\n",
    "\n",
    "# -------------------- Train and Select Best Model --------------------\n",
    "def train_and_select(\n",
    "    X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray\n",
    "):\n",
    "    lr = train_logistic_regression(X_train, y_train)\n",
    "    lr_acc = lr.score(X_val, y_val)\n",
    "    print(f\"Logistic Regression - Validation accuracy: {lr_acc:.4f}\", end=\"\")\n",
    "\n",
    "    best_model, best_score, best_name = lr, lr_acc, \"LogisticRegression\"\n",
    "\n",
    "    for h in range(3, 65):\n",
    "        print(f\"Fitting MLPClassifier with hidden layer size {h}...\")\n",
    "        mlp = MLPClassifier(\n",
    "            hidden_layer_sizes=(h,),\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1,\n",
    "            n_iter_no_change=5,\n",
    "            max_iter=200,\n",
    "            random_state=42,\n",
    "            verbose=True,\n",
    "        )\n",
    "        mlp.fit(X_train, y_train)\n",
    "        val_acc = accuracy_score(y_val, mlp.predict(X_val))\n",
    "        print(f\"MLPClassifier (hidden={h}) - Validation accuracy: {val_acc:.4f}\")\n",
    "        if val_acc > best_score:\n",
    "            best_model, best_score, best_name = (\n",
    "                mlp,\n",
    "                val_acc,\n",
    "                f\"MLPClassifier(hidden={h})\",\n",
    "            )\n",
    "\n",
    "    print(f\"Best model: {best_name} with validation accuracy: {best_score:.4f}\")\n",
    "    return best_model\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val = load_split_save(\n",
    "    \"train.csv\", \"val.csv\", train_size=1_000_000, val_size=100_000\n",
    ")\n",
    "best_model = train_and_select(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb1832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing train: 100%|██████████| 1000000/1000000 [01:16<00:00, 13138.70it/s]\n",
      "Featurizing val: 100%|██████████| 100000/100000 [00:07<00:00, 13282.58it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 3, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [-1.  0.  1.]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train, y_train, X_val, y_val \u001b[38;5;241m=\u001b[39m load_split_save(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1_000_000\u001b[39m, val_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100_000\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n\u001b[1;32m----> 5\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 79\u001b[0m, in \u001b[0;36mtrain_and_select\u001b[1;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     77\u001b[0m lr \u001b[38;5;241m=\u001b[39m train_logistic_regression(X_train, y_train)\n\u001b[0;32m     78\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(lr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m lr_loss \u001b[38;5;241m=\u001b[39m \u001b[43mlog_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_prob\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m y_prob \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     80\u001b[0m lr_acc \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mscore(X_val, y_val)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression - Validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\forbe\\.local\\share\\mamba\\envs\\chess\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\forbe\\.local\\share\\mamba\\envs\\chess\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2968\u001b[0m, in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, normalize, sample_weight, labels)\u001b[0m\n\u001b[0;32m   2966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lb\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m!=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m   2967\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2968\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2969\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true and y_pred contain different number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2970\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Please provide the true \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2971\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels explicitly through the labels argument. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2972\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasses found in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2973\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true: \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2974\u001b[0m                 transformed_labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], lb\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   2975\u001b[0m             )\n\u001b[0;32m   2976\u001b[0m         )\n\u001b[0;32m   2977\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2979\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of classes in labels is different \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2980\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom that in y_pred. Classes found in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2981\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(lb\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m   2982\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 3, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [-1.  0.  1.]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d2e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3dc9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c02e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
