{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from utils import fen_to_binary_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_games_in_pgn(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "    return content.count(\"[Event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgn_to_dataframe(pgn_file_path):\n",
    "    \"\"\"\n",
    "    Parse a PGN file and create a DataFrame where each row represents a position.\n",
    "    Columns in the DataFrame:\n",
    "        - game_id\n",
    "        - move_number\n",
    "        - board_fen\n",
    "        - move\n",
    "        - result (e.g. '1-0', '0-1', '1/2-1/2')\n",
    "    \"\"\"\n",
    "    all_positions = []\n",
    "    game_id = 0\n",
    "\n",
    "    with open(pgn_file_path, \"r\", encoding=\"utf-8\") as pgn:\n",
    "        for i in tqdm(range(count_games_in_pgn(pgn_file_path))):\n",
    "            game = chess.pgn.read_game(pgn)\n",
    "            if game is None:\n",
    "                break\n",
    "\n",
    "            game_id += 1\n",
    "            result = game.headers.get(\"Result\", \"*\")\n",
    "            board = game.board()\n",
    "\n",
    "            move_number = 0\n",
    "            for move in game.mainline_moves():\n",
    "                board.push(move)\n",
    "                move_number += 1\n",
    "                position_data = {\n",
    "                    \"game_id\": game_id,\n",
    "                    \"move_number\": move_number,\n",
    "                    \"board_fen\": board.fen(),\n",
    "                    \"move\": move.uci(),\n",
    "                    \"result\": result,\n",
    "                }\n",
    "                all_positions.append(position_data)\n",
    "\n",
    "    df = pd.DataFrame(all_positions)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgn_path = r\"C:\\Users\\forbe\\Downloads\\lichess_elite_2024-10\\lichess_elite_2024-10.pgn\"\n",
    "# df_positions = pgn_to_dataframe(pgn_path)\n",
    "# df_positions.to_parquet(r\"C:\\Users\\forbe\\OneDrive\\Personal\\Documents\\repos\\chess_data\\df_positions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_positions = pd.read_parquet(r\"C:\\Users\\forbe\\OneDrive\\Personal\\Documents\\repos\\chess_data\\df_positions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_MAPPING = {\"1-0\": 2, \"0-1\": 0, \"1/2-1/2\": 1}\n",
    "\n",
    "\n",
    "def split_dataframe(df, chunk_size):\n",
    "    return [df[i : i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "\n",
    "def df_fen_to_binary_perspective(\n",
    "    df: pd.DataFrame, fen_column: str = \"board_fen\", result_column: str = \"result\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a DataFrame that has columns:\n",
    "      - fen_column (default 'board_fen'): FEN strings\n",
    "      - result_column (default 'result'): game result\n",
    "    Convert each FEN to a 780-dim feature vector from the side-to-move perspective.\n",
    "\n",
    "    Adjust the result to reflect the perspective of the side to move.\n",
    "\n",
    "    Returns a new DataFrame with:\n",
    "      - 768 columns for piece placement\n",
    "      - 4 columns for castling rights\n",
    "      - 8 columns for en passant\n",
    "      - 'result' column (adjusted to the side to move)\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    adjusted_results = []\n",
    "\n",
    "    for fen, result in zip(df[fen_column], df[result_column]):\n",
    "        # Extract features from the perspective of the side to move\n",
    "        board = chess.Board(fen)\n",
    "        side_to_move = board.turn  # True for White, False for Black\n",
    "\n",
    "        if not side_to_move:  # Black to move\n",
    "            # Adjust the result: swap \"1-0\" with \"0-1\"\n",
    "            if result == \"1-0\":\n",
    "                adjusted_result = \"0-1\"\n",
    "            elif result == \"0-1\":\n",
    "                adjusted_result = \"1-0\"\n",
    "            else:\n",
    "                adjusted_result = result  # Draw remains the same\n",
    "        else:\n",
    "            adjusted_result = result  # White to move, no adjustment needed\n",
    "\n",
    "        # Convert FEN to binary features\n",
    "        feature_vec = fen_to_binary_features(board.fen())\n",
    "        feature_list.append(feature_vec)\n",
    "        adjusted_results.append(adjusted_result)\n",
    "\n",
    "    # Convert the list of numpy arrays to a 2D array\n",
    "    feature_array = np.vstack(feature_list)\n",
    "\n",
    "    # Create column names\n",
    "    column_names = (\n",
    "        [f\"piece_placement_{i}\" for i in range(768)]\n",
    "        + [f\"castling_{i}\" for i in range(4)]\n",
    "        + [f\"en_passant_{i}\" for i in range(8)]\n",
    "    )\n",
    "\n",
    "    # Build the DataFrame of features\n",
    "    df_features = pd.DataFrame(feature_array, columns=column_names, index=df.index)\n",
    "\n",
    "    # Add the adjusted result column, mapping it to numeric labels\n",
    "    df_features[result_column] = adjusted_results\n",
    "    df_features[result_column] = df_features[result_column].map(RESULT_MAPPING)\n",
    "\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fen_to_binary_perspective(df_positions.iloc[:100]).diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_positions = list(df_positions[df_positions.move_number == 4].board_fen.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chess.Board(top_positions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features = pd.concat([df_fen_to_binary_perspective(sub_df) for sub_df in tqdm(split_dataframe(df_positions.sample(frac=1, random_state=42).reset_index(drop=True), 100_000)[:10])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features.to_parquet(r\"C:\\Users\\forbe\\OneDrive\\Personal\\Documents\\repos\\chess_data\\df_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_classifier(X, Y):\n",
    "    # Split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        Y,\n",
    "        test_size=0.20,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Optional: scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize MLP\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(16), random_state=42, verbose=True, early_stopping=True\n",
    "    )\n",
    "\n",
    "    print(\"ready to train\")\n",
    "\n",
    "    # Fit (train) the model\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = mlp.score(X_test_scaled, y_test)\n",
    "    print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "    y_pred = mlp.predict(X_test_scaled)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    # Return the trained classifier and scaler\n",
    "    return mlp, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_parquet(\n",
    "    r\"C:\\Users\\forbe\\OneDrive\\Personal\\Documents\\repos\\chess_data\\df_features.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=600)  # Number of components you want\n",
    "# pca_features = pca.fit_transform(df_features[list(df_features.columns)[:-1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_categories = [\n",
    "    \"player_pawns\",\n",
    "    \"player_knights\",\n",
    "    \"player_bishops\",\n",
    "    \"player_rooks\",\n",
    "    \"player_queens\",\n",
    "    \"player_kings\",\n",
    "    \"opponent_pawns\",\n",
    "    \"opponent_knights\",\n",
    "    \"opponent_bishops\",\n",
    "    \"opponent_rooks\",\n",
    "    \"opponent_queens\",\n",
    "    \"opponent_kings\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, piece in enumerate(piece_categories):\n",
    "#     df_features[piece] =  np.sum(df_features.iloc[:,list(np.arange(64)*12 + i)], axis=1)#np.sum(df_features[df_features.columns[i*64:i*64+64]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_feature_lookup = {}\n",
    "\n",
    "for i, piece in enumerate(piece_categories):\n",
    "    piece_feature_lookup[piece] = df_features.iloc[\n",
    "        :, list(np.arange(64) * 12 + i)\n",
    "    ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pieces = np.sum(df_features[df_features.columns[:728]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pieces = np.sum(df_features[df_features.columns[:728]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_features[df_features.columns[:-1]].values #\n",
    "X = piece_feature_lookup[\"player_kings\"][total_pieces < 10]\n",
    "Y = df_features[\"result\"][total_pieces < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression().fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cmap = plt.cm.RdYlGn\n",
    "plot_array = logistic_model.coef_[2].reshape(8, 8)[::-1]\n",
    "norm = mcolors.Normalize(vmin=np.min(plot_array), vmax=np.max(plot_array))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(plot_array, cmap=cmap, norm=norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_scaler = StandardScaler()\n",
    "logistic_model = LogisticRegression().fit(logistic_scaler.fit_transform(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.predict_proba(logistic_scaler.transform(X[5000].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pkl/logistic_model.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(logistic_model, f)\n",
    "\n",
    "# with open(\"pkl/logistic_scaler.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(logistic_scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_model, feature_scaler = train_mlp_classifier(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pkl/mlp_model.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(mlp_model, f)\n",
    "\n",
    "# with open(\"pkl/mlp_scaler.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(feature_scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
