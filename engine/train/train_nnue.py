"""NNUE training pipeline.

Reads binary .bin training data generated by the C++ self-play engine,
trains a small NNUE (773 -> 256 -> 32 -> 1) with ClippedReLU activations.
C++ inference uses tanh on the single output, scaled by MATE_VALUE.
Training returns tanh of the single output and uses MSE loss against a
blended target of search eval and game result.
"""

import argparse
import os
import sys
import warnings
from pathlib import Path

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset

sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))
from config.load_config import engine, training

warnings.filterwarnings("ignore", message="Cannot set number of intraop threads")
torch.set_num_threads(os.cpu_count())

_eng = engine()
_trn = training()

POSITION_SIZE = 42  # bytes per training position (binary struct layout)

INPUT_SIZE = _trn["nnue"]["input_size"]
HIDDEN1_SIZE = _trn["nnue"]["hidden1_size"]
HIDDEN2_SIZE = _trn["nnue"]["hidden2_size"]
OUTPUT_SIZE = _trn["nnue"]["output_size"]


class NNUE(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(INPUT_SIZE, HIDDEN1_SIZE)
        self.fc2 = nn.Linear(HIDDEN1_SIZE, HIDDEN2_SIZE)
        self.fc3 = nn.Linear(HIDDEN2_SIZE, OUTPUT_SIZE)
        self.crelu = nn.Hardtanh(0.0, 1.0)

    def forward(self, x):
        x = self.crelu(self.fc1(x))
        x = self.crelu(self.fc2(x))
        return torch.tanh(self.fc3(x)).squeeze(-1)  # range [-1, 1]


def extract_features(piece_placement, side_to_move, castling=0, en_passant_file=255):
    """Extract 773 features from binary position data.

    Features are from side-to-move perspective:
    - 0-383: own pieces (6 types x 64 squares)
    - 384-767: opponent pieces (6 types x 64 squares)
    - 768-771: castling (own KS, own QS, opp KS, opp QS)
    - 772: en passant available

    When black to move, the board is vertically flipped.
    """
    features = np.zeros(INPUT_SIZE, dtype=np.float32)
    white_to_move = side_to_move == 0

    # Vectorized nibble extraction: decode all 64 squares at once
    raw = np.frombuffer(piece_placement, dtype=np.uint8)
    high = (raw >> 4) & 0x0F  # even squares
    low = raw & 0x0F  # odd squares
    nibbles = np.empty(64, dtype=np.uint8)
    nibbles[0::2] = high
    nibbles[1::2] = low

    # Find non-empty squares
    occupied = np.nonzero(nibbles)[0]
    for sq in occupied:
        nibble = int(nibbles[sq])
        if nibble <= 6:
            piece_type, piece_color = nibble - 1, 0
        else:
            piece_type, piece_color = nibble - 7, 1

        is_own = (piece_color == 0) == white_to_move
        feature_sq = sq if white_to_move else (sq ^ 56)
        offset = 0 if is_own else 384
        features[offset + piece_type * 64 + feature_sq] = 1.0

    # Castling rights from STM perspective
    # Binary encoding: bit3=WK, bit2=WQ, bit1=BK, bit0=BQ
    if white_to_move:
        features[768] = float((castling >> 3) & 1)
        features[769] = float((castling >> 2) & 1)
        features[770] = float((castling >> 1) & 1)
        features[771] = float(castling & 1)
    else:
        features[768] = float((castling >> 1) & 1)
        features[769] = float(castling & 1)
        features[770] = float((castling >> 3) & 1)
        features[771] = float((castling >> 2) & 1)

    features[772] = float(en_passant_file != 255)

    return features


MAX_ACTIVE = 37  # 32 pieces + 4 castling + 1 EP


def _extract_sparse(data: bytes, num_positions: int, eval_weight: float):
    """Extract sparse feature indices and targets from binary data.

    Returns (indices, counts, targets) where:
    - indices: (N, MAX_ACTIVE) int16, padded with 0
    - counts: (N,) uint8, number of active features per position
    - targets: (N,) float32
    """
    mate_value = float(_eng["mate_value"])

    raw = np.frombuffer(data, dtype=np.uint8).reshape(num_positions, POSITION_SIZE)

    # Decode piece nibbles
    piece_bytes = raw[:, :32]
    high = (piece_bytes >> 4) & 0x0F
    low = piece_bytes & 0x0F
    nibbles = np.empty((num_positions, 64), dtype=np.uint8)
    nibbles[:, 0::2] = high
    nibbles[:, 1::2] = low

    side_to_move = raw[:, 32]
    castling = raw[:, 33]
    en_passant_file = raw[:, 34]

    # Targets
    eval_bytes = raw[:, 35:39].copy()
    search_eval = eval_bytes.view(np.float32).reshape(num_positions)
    eval_scalar = np.clip(search_eval / mate_value, -1.0, 1.0)
    result_scalar = raw[:, 39].astype(np.float32) - 1.0
    targets = eval_weight * eval_scalar + (1.0 - eval_weight) * result_scalar

    # Sparse feature indices
    white_to_move = side_to_move == 0
    indices = np.zeros((num_positions, MAX_ACTIVE), dtype=np.int16)
    counts = np.zeros(num_positions, dtype=np.uint8)

    for sq in range(64):
        nib = nibbles[:, sq]
        occupied = nib > 0
        occ_idx = np.where(occupied)[0]
        if len(occ_idx) == 0:
            continue

        nib_occ = nib[occ_idx].astype(np.int32)
        is_white_piece = nib_occ <= 6
        piece_type = np.where(is_white_piece, nib_occ - 1, nib_occ - 7)
        is_own = is_white_piece == white_to_move[occ_idx]
        feature_sq = np.where(white_to_move[occ_idx], sq, sq ^ 56)
        feat_idx = np.where(is_own, 0, 384) + piece_type * 64 + feature_sq

        c = counts[occ_idx]
        indices[occ_idx, c] = feat_idx.astype(np.int16)
        counts[occ_idx] = c + 1

    # Castling
    wk = (castling >> 3) & 1
    wq = (castling >> 2) & 1
    bk = (castling >> 1) & 1
    bq = castling & 1

    cast_feats = np.stack(
        [
            np.where(white_to_move, wk, bk),
            np.where(white_to_move, wq, bq),
            np.where(white_to_move, bk, wk),
            np.where(white_to_move, bq, wq),
        ],
        axis=1,
    )  # (N, 4)

    for i in range(4):
        active = cast_feats[:, i] > 0
        active_idx = np.where(active)[0]
        if len(active_idx) > 0:
            c = counts[active_idx]
            indices[active_idx, c] = np.int16(768 + i)
            counts[active_idx] = c + 1

    # En passant
    ep_active = en_passant_file != 255
    ep_idx = np.where(ep_active)[0]
    if len(ep_idx) > 0:
        c = counts[ep_idx]
        indices[ep_idx, c] = np.int16(772)
        counts[ep_idx] = c + 1

    plies = raw[:, 40:42].copy().view(np.uint16).reshape(num_positions)

    return indices, counts, targets, plies


class SelfPlayDataset(Dataset):
    """Dataset storing sparse feature indices for memory efficiency.

    15M positions: ~1.2 GB (sparse) vs ~48 GB (dense float32).
    """

    def __init__(self, filepath, eval_weight=0.75):
        file_size = Path(filepath).stat().st_size
        num_positions = file_size // POSITION_SIZE

        with open(filepath, "rb") as f:
            data = f.read()

        print(f"Pre-extracting {num_positions} positions (sparse)...")
        indices, counts, targets, plies = _extract_sparse(
            data, num_positions, eval_weight
        )
        self.indices = torch.from_numpy(indices)  # (N, 37) int16
        self.counts = torch.from_numpy(counts)  # (N,) uint8
        self.targets = torch.from_numpy(targets)  # (N,) float32
        self.plies = plies  # (N,) uint16 numpy array
        print("Pre-extraction complete.")

    def __len__(self):
        return len(self.targets)

    def __getitem__(self, idx):
        return self.indices[idx], self.counts[idx], self.targets[idx]

    def get_dense(self, idx):
        """Return (dense_features, target) for a single position."""
        features = torch.zeros(INPUT_SIZE, dtype=torch.float32)
        n = self.counts[idx]
        features[self.indices[idx, :n].long()] = 1.0
        return features, self.targets[idx]


def _game_boundaries(plies):
    """Find game boundaries from ply resets.

    Returns (starts, ends) where game i spans positions [starts[i], ends[i]).
    """
    n = len(plies)
    if n == 0:
        return np.array([], dtype=np.intp), np.array([], dtype=np.intp)
    boundaries = np.where(np.diff(plies.astype(np.int32)) <= 0)[0] + 1
    starts = np.concatenate([[0], boundaries])
    ends = np.concatenate([boundaries, [n]])
    return starts, ends


def train(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    num_cores = os.cpu_count()
    print(f"Using device: {device}, threads: {num_cores}")

    dataset = SelfPlayDataset(args.data, eval_weight=args.eval_weight)
    num_positions = len(dataset)
    print(f"Loaded {num_positions} positions from {args.data}")

    # Game-level split to prevent data leakage from correlated positions
    game_starts, game_ends = _game_boundaries(dataset.plies)
    num_games = len(game_starts)

    if num_games >= 2:
        game_perm = torch.randperm(num_games)
        val_game_count = max(1, int(num_games * _trn["training"]["val_split"]))
        val_game_count = min(val_game_count, num_games - 1)

        val_idx = torch.cat(
            [
                torch.arange(int(game_starts[g]), int(game_ends[g]))
                for g in game_perm[:val_game_count].tolist()
            ]
        )
        train_idx = torch.cat(
            [
                torch.arange(int(game_starts[g]), int(game_ends[g]))
                for g in game_perm[val_game_count:].tolist()
            ]
        )
        print(
            f"Game-level split: {num_games} games, "
            f"{num_games - val_game_count} train / {val_game_count} val"
        )
    else:
        perm = torch.randperm(num_positions)
        val_count = max(1, int(num_positions * _trn["training"]["val_split"]))
        val_idx = perm[:val_count]
        train_idx = perm[val_count:]

    train_size = len(train_idx)
    val_size = len(val_idx)

    # Pre-slice val set (never shuffled)
    val_indices = dataset.indices[val_idx]
    val_counts = dataset.counts[val_idx]
    val_targets = dataset.targets[val_idx]

    use_cuda = device.type == "cuda"
    model = NNUE().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
    scaler = torch.amp.GradScaler(enabled=use_cuda)

    best_val_loss = float("inf")
    patience_counter = 0
    best_state = None
    epoch_log = []
    batch_size = args.batch_size

    def sparse_to_dense(idx_batch, cnt_batch):
        B = idx_batch.shape[0]
        max_c = int(cnt_batch.max())
        active = idx_batch[:, :max_c].long()
        mask = torch.arange(max_c).unsqueeze(0) < cnt_batch.unsqueeze(1)
        features = torch.zeros(B, INPUT_SIZE, dtype=torch.float32)
        features.scatter_(1, active * mask.long(), mask.float())
        return features

    for epoch in range(args.epochs):
        # Training: shuffle train indices each epoch
        shuf = train_idx[torch.randperm(train_size)]
        model.train()
        train_loss = 0.0
        for start in range(0, train_size, batch_size):
            batch = shuf[start : start + batch_size]
            features = sparse_to_dense(
                dataset.indices[batch], dataset.counts[batch]
            ).to(device)
            targets = dataset.targets[batch].to(device)

            with torch.amp.autocast(device_type=device.type, enabled=use_cuda):
                output = model(features)
                loss = F.mse_loss(output, targets)

            optimizer.zero_grad()
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            train_loss += loss.item() * len(batch)

        train_loss /= train_size

        # Validation
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for start in range(0, val_size, batch_size):
                end = min(start + batch_size, val_size)
                features = sparse_to_dense(
                    val_indices[start:end], val_counts[start:end]
                ).to(device)
                targets = val_targets[start:end].to(device)
                with torch.amp.autocast(device_type=device.type, enabled=use_cuda):
                    output = model(features)
                    loss = F.mse_loss(output, targets)
                val_loss += loss.item() * (end - start)

        val_loss /= val_size

        improved = val_loss < best_val_loss
        epoch_log.append((epoch + 1, train_loss, val_loss, improved))

        print(
            f"Epoch {epoch + 1}/{args.epochs} - "
            f"train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}"
        )

        # Early stopping
        if improved:
            best_val_loss = val_loss
            patience_counter = 0
            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}
            if args.output:
                torch.save(best_state, args.output)
                print(f"  Saved best model to {args.output}")
        else:
            patience_counter += 1
            if patience_counter >= args.patience:
                print(f"Early stopping at epoch {epoch + 1}")
                break

    print(f"Training complete. Best val loss: {best_val_loss:.4f}")
    if args.output:
        print(f"Model saved to {args.output}")

    if getattr(args, "log", None):
        _write_log(args, num_positions, epoch_log, best_val_loss)

    return best_state


def _write_log(args, num_positions, epoch_log, best_val_loss):
    log_path = Path(args.log)
    log_path.parent.mkdir(parents=True, exist_ok=True)
    lines = [
        "# Training Log",
        "",
        f"- **Positions**: {num_positions:,}",
        f"- **Batch size**: {args.batch_size}",
        f"- **Learning rate**: {args.lr}",
        f"- **Eval weight**: {args.eval_weight}",
        f"- **Best val loss**: {best_val_loss:.6f}",
        f"- **Epochs run**: {len(epoch_log)}/{args.epochs}",
        "",
        "| Epoch | Train Loss | Val Loss | Best |",
        "|------:|-----------:|---------:|:----:|",
    ]
    for epoch, tl, vl, improved in epoch_log:
        marker = "*" if improved else ""
        lines.append(f"| {epoch} | {tl:.6f} | {vl:.6f} | {marker} |")
    lines.append("")
    log_path.write_text("\n".join(lines))
    print(f"Training log written to {log_path}")


def main():
    parser = argparse.ArgumentParser(description="Train NNUE from self-play data")
    parser.add_argument(
        "--data", required=True, help="Path to binary training data (.bin)"
    )
    parser.add_argument(
        "--output", default="nnue_weights.pt", help="Output PyTorch model path"
    )
    parser.add_argument("--epochs", type=int, default=_trn["training"]["epochs"])
    parser.add_argument(
        "--batch-size", type=int, default=_trn["training"]["batch_size"]
    )
    parser.add_argument("--lr", type=float, default=_trn["training"]["lr"])
    parser.add_argument("--patience", type=int, default=_trn["training"]["patience"])
    parser.add_argument(
        "--eval-weight",
        type=float,
        default=_trn["training"]["eval_weight"],
        help="Weight for search eval vs game result in target (0-1)",
    )
    parser.add_argument(
        "--log",
        help="Path to write training log as markdown (.md)",
    )
    args = parser.parse_args()

    train(args)


if __name__ == "__main__":
    main()
