"""NNUE training pipeline.

Reads binary .bin training data generated by the C++ self-play engine,
trains a small NNUE (768 -> 256 -> 32 -> 3) with ClippedReLU activations,
and outputs [P(win), P(draw), P(loss)] from side-to-move's perspective.
"""

import argparse
import struct
from pathlib import Path

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset, random_split

POSITION_SIZE = 42  # bytes per training position

INPUT_SIZE = 768
HIDDEN1_SIZE = 256
HIDDEN2_SIZE = 32
OUTPUT_SIZE = 3


class NNUE(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(INPUT_SIZE, HIDDEN1_SIZE)
        self.fc2 = nn.Linear(HIDDEN1_SIZE, HIDDEN2_SIZE)
        self.fc3 = nn.Linear(HIDDEN2_SIZE, OUTPUT_SIZE)
        self.crelu = nn.Hardtanh(0.0, 1.0)

    def forward(self, x):
        x = self.crelu(self.fc1(x))
        x = self.crelu(self.fc2(x))
        x = self.fc3(x)
        return F.softmax(x, dim=-1)


def decode_piece(nibble):
    """Decode 4-bit piece encoding to (piece_type_0_5, is_own_piece).

    Encoding: 0=empty, 1-6=white P/N/B/R/Q/K, 7-12=black P/N/B/R/Q/K.
    """
    if nibble == 0:
        return None, None
    if nibble <= 6:
        return nibble - 1, 0  # white piece, piece_type 0-5
    return nibble - 7, 1  # black piece, piece_type 0-5


def extract_features(piece_placement, side_to_move):
    """Extract 768 features from binary piece placement.

    Features are from side-to-move perspective:
    - 0-383: own pieces (6 types x 64 squares)
    - 384-767: opponent pieces (6 types x 64 squares)

    When black to move, the board is vertically flipped.
    """
    features = np.zeros(INPUT_SIZE, dtype=np.float32)
    white_to_move = side_to_move == 0

    for sq in range(64):
        byte_idx = sq // 2
        if sq % 2 == 0:
            nibble = (piece_placement[byte_idx] >> 4) & 0x0F
        else:
            nibble = piece_placement[byte_idx] & 0x0F

        if nibble == 0:
            continue

        piece_type, piece_color = decode_piece(nibble)

        # Determine if this is our piece or opponent's
        is_own = (piece_color == 0) == white_to_move

        # Flip square if black to move
        feature_sq = sq if white_to_move else (sq ^ 56)

        offset = 0 if is_own else 384
        idx = offset + piece_type * 64 + feature_sq
        features[idx] = 1.0

    return features


class SelfPlayDataset(Dataset):
    """Dataset reading binary training positions."""

    def __init__(self, filepath, eval_weight=0.75):
        self.filepath = filepath
        self.eval_weight = eval_weight

        file_size = Path(filepath).stat().st_size
        self.num_positions = file_size // POSITION_SIZE

        with open(filepath, "rb") as f:
            self.data = f.read()

    def __len__(self):
        return self.num_positions

    def __getitem__(self, idx):
        offset = idx * POSITION_SIZE
        raw = self.data[offset : offset + POSITION_SIZE]

        piece_placement = raw[0:32]
        side_to_move = raw[32]
        search_eval = struct.unpack("<f", raw[35:39])[0]
        game_result = raw[39]

        features = extract_features(piece_placement, side_to_move)

        # Eval target: sigmoid scaling of centipawn eval to [P(win), P(draw), P(loss)]
        p_win = 1.0 / (1.0 + np.exp(-search_eval / 400.0))
        eval_target = np.array([p_win, 0.0, 1.0 - p_win], dtype=np.float32)

        # Result target: one-hot [win, draw, loss] from game_result (0=loss, 1=draw, 2=win)
        result_target = np.zeros(3, dtype=np.float32)
        result_target[2 - game_result] = 1.0

        # Blend eval and result targets
        target = (
            self.eval_weight * eval_target + (1.0 - self.eval_weight) * result_target
        )
        # Normalize to sum to 1
        target /= target.sum()

        return torch.from_numpy(features), torch.from_numpy(target)


def train(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    dataset = SelfPlayDataset(args.data, eval_weight=args.eval_weight)
    print(f"Loaded {len(dataset)} positions from {args.data}")

    # Split into train/val
    val_size = max(1, int(len(dataset) * 0.1))
    train_size = len(dataset) - val_size
    train_set, val_set = random_split(
        dataset,
        [train_size, val_size],
        generator=torch.Generator().manual_seed(42),
    )

    train_loader = DataLoader(
        train_set, batch_size=args.batch_size, shuffle=True, num_workers=0
    )
    val_loader = DataLoader(
        val_set, batch_size=args.batch_size, shuffle=False, num_workers=0
    )

    model = NNUE().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, patience=3, factor=0.5
    )

    best_val_loss = float("inf")
    patience_counter = 0

    for epoch in range(args.epochs):
        # Training
        model.train()
        train_loss = 0.0
        for features, targets in train_loader:
            features, targets = features.to(device), targets.to(device)

            output = model(features)
            # Cross-entropy with soft targets
            loss = -(targets * torch.log(output + 1e-8)).sum(dim=-1).mean()

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * features.size(0)

        train_loss /= train_size

        # Validation
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for features, targets in val_loader:
                features, targets = features.to(device), targets.to(device)
                output = model(features)
                loss = -(targets * torch.log(output + 1e-8)).sum(dim=-1).mean()
                val_loss += loss.item() * features.size(0)

        val_loss /= val_size
        scheduler.step(val_loss)

        print(
            f"Epoch {epoch + 1}/{args.epochs} - "
            f"train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}, "
            f"lr: {optimizer.param_groups[0]['lr']:.2e}"
        )

        # Early stopping
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            torch.save(model.state_dict(), args.output)
            print(f"  Saved best model to {args.output}")
        else:
            patience_counter += 1
            if patience_counter >= args.patience:
                print(f"Early stopping at epoch {epoch + 1}")
                break

    print(f"Training complete. Best val loss: {best_val_loss:.4f}")
    print(f"Model saved to {args.output}")


def main():
    parser = argparse.ArgumentParser(description="Train NNUE from self-play data")
    parser.add_argument(
        "--data", required=True, help="Path to binary training data (.bin)"
    )
    parser.add_argument(
        "--output", default="nnue_weights.pt", help="Output PyTorch model path"
    )
    parser.add_argument("--epochs", type=int, default=100)
    parser.add_argument("--batch-size", type=int, default=4096)
    parser.add_argument("--lr", type=float, default=1e-3)
    parser.add_argument("--patience", type=int, default=10)
    parser.add_argument(
        "--eval-weight",
        type=float,
        default=0.75,
        help="Weight for search eval vs game result in target (0-1)",
    )
    args = parser.parse_args()

    train(args)


if __name__ == "__main__":
    main()
