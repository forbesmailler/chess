"""NNUE training pipeline.

Reads binary .bin training data generated by the C++ self-play engine,
trains a small NNUE (773 -> 256 -> 32 -> 1) with ClippedReLU activations.
C++ inference uses tanh on the single output, scaled by MATE_VALUE.
Training returns tanh of the single output and uses MSE loss against a
blended target of search eval and game result.
"""

import argparse
import os
import sys
import warnings
from pathlib import Path

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset, random_split

sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))
from config.load_config import engine, training

warnings.filterwarnings("ignore", message="Cannot set number of intraop threads")
torch.set_num_threads(os.cpu_count())

_eng = engine()
_trn = training()

POSITION_SIZE = 42  # bytes per training position (binary struct layout)

INPUT_SIZE = _eng["nnue"]["input_size"]
HIDDEN1_SIZE = _eng["nnue"]["hidden1_size"]
HIDDEN2_SIZE = _eng["nnue"]["hidden2_size"]
OUTPUT_SIZE = _eng["nnue"]["output_size"]


class NNUE(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(INPUT_SIZE, HIDDEN1_SIZE)
        self.fc2 = nn.Linear(HIDDEN1_SIZE, HIDDEN2_SIZE)
        self.fc3 = nn.Linear(HIDDEN2_SIZE, OUTPUT_SIZE)
        self.crelu = nn.Hardtanh(0.0, 1.0)

    def forward(self, x):
        x = self.crelu(self.fc1(x))
        x = self.crelu(self.fc2(x))
        return torch.tanh(self.fc3(x)).squeeze(-1)  # range [-1, 1]


def extract_features(piece_placement, side_to_move, castling=0, en_passant_file=255):
    """Extract 773 features from binary position data.

    Features are from side-to-move perspective:
    - 0-383: own pieces (6 types x 64 squares)
    - 384-767: opponent pieces (6 types x 64 squares)
    - 768-771: castling (own KS, own QS, opp KS, opp QS)
    - 772: en passant available

    When black to move, the board is vertically flipped.
    """
    features = np.zeros(INPUT_SIZE, dtype=np.float32)
    white_to_move = side_to_move == 0

    # Vectorized nibble extraction: decode all 64 squares at once
    raw = np.frombuffer(piece_placement, dtype=np.uint8)
    high = (raw >> 4) & 0x0F  # even squares
    low = raw & 0x0F  # odd squares
    nibbles = np.empty(64, dtype=np.uint8)
    nibbles[0::2] = high
    nibbles[1::2] = low

    # Find non-empty squares
    occupied = np.nonzero(nibbles)[0]
    for sq in occupied:
        nibble = int(nibbles[sq])
        if nibble <= 6:
            piece_type, piece_color = nibble - 1, 0
        else:
            piece_type, piece_color = nibble - 7, 1

        is_own = (piece_color == 0) == white_to_move
        feature_sq = sq if white_to_move else (sq ^ 56)
        offset = 0 if is_own else 384
        features[offset + piece_type * 64 + feature_sq] = 1.0

    # Castling rights from STM perspective
    # Binary encoding: bit3=WK, bit2=WQ, bit1=BK, bit0=BQ
    if white_to_move:
        features[768] = float((castling >> 3) & 1)
        features[769] = float((castling >> 2) & 1)
        features[770] = float((castling >> 1) & 1)
        features[771] = float(castling & 1)
    else:
        features[768] = float((castling >> 1) & 1)
        features[769] = float(castling & 1)
        features[770] = float((castling >> 3) & 1)
        features[771] = float((castling >> 2) & 1)

    features[772] = float(en_passant_file != 255)

    return features


def _extract_all(data: bytes, num_positions: int, eval_weight: float):
    """Vectorized extraction of all positions into feature and target arrays."""
    mate_value = float(_eng["mate_value"])

    raw = np.frombuffer(data, dtype=np.uint8).reshape(num_positions, POSITION_SIZE)

    # Decode piece nibbles: 32 bytes -> 64 nibbles per position
    piece_bytes = raw[:, :32]
    high = (piece_bytes >> 4) & 0x0F  # even squares
    low = piece_bytes & 0x0F  # odd squares
    nibbles = np.empty((num_positions, 64), dtype=np.uint8)
    nibbles[:, 0::2] = high
    nibbles[:, 1::2] = low

    side_to_move = raw[:, 32]  # (N,)
    castling = raw[:, 33]
    en_passant_file = raw[:, 34]

    # Targets: eval + result blending
    eval_bytes = raw[:, 35:39].copy()
    search_eval = eval_bytes.view(np.float32).reshape(num_positions)
    eval_scalar = np.clip(search_eval / mate_value, -1.0, 1.0)
    result_scalar = raw[:, 39].astype(np.float32) - 1.0
    targets = eval_weight * eval_scalar + (1.0 - eval_weight) * result_scalar

    # Vectorized feature extraction
    white_to_move = side_to_move == 0  # (N,)
    features = np.zeros((num_positions, INPUT_SIZE), dtype=np.float32)

    for sq in range(64):
        nib = nibbles[:, sq]  # (N,)
        occupied = nib > 0

        # Piece type and color from nibble
        is_white_piece = (nib >= 1) & (nib <= 6)
        nib_int = nib.astype(np.int32)
        piece_type = np.where(is_white_piece, nib_int - 1, nib_int - 7)  # 0-5

        # Is this piece "own" from STM perspective?
        is_own = (is_white_piece == white_to_move) & occupied

        # Feature square: flip for black STM
        feature_sq = np.where(white_to_move, np.int32(sq), np.int32(sq ^ 56))

        # Feature index: offset + piece_type * 64 + feature_sq
        own_idx = piece_type * 64 + feature_sq
        opp_idx = 384 + piece_type * 64 + feature_sq

        # Set features for occupied squares
        own_mask = occupied & is_own
        opp_mask = occupied & ~is_own

        pos_indices = np.where(own_mask)[0]
        if len(pos_indices) > 0:
            features[pos_indices, own_idx[pos_indices]] = 1.0

        pos_indices = np.where(opp_mask)[0]
        if len(pos_indices) > 0:
            features[pos_indices, opp_idx[pos_indices]] = 1.0

    # Castling: 4 features (768-771)
    wk = (castling >> 3) & 1
    wq = (castling >> 2) & 1
    bk = (castling >> 1) & 1
    bq = castling & 1
    features[:, 768] = np.where(white_to_move, wk, bk).astype(np.float32)
    features[:, 769] = np.where(white_to_move, wq, bq).astype(np.float32)
    features[:, 770] = np.where(white_to_move, bk, wk).astype(np.float32)
    features[:, 771] = np.where(white_to_move, bq, wq).astype(np.float32)

    # En passant
    features[:, 772] = (en_passant_file != 255).astype(np.float32)

    return features, targets


class SelfPlayDataset(Dataset):
    """Dataset that pre-extracts all features and targets at load time."""

    def __init__(self, filepath, eval_weight=0.75):
        file_size = Path(filepath).stat().st_size
        num_positions = file_size // POSITION_SIZE

        with open(filepath, "rb") as f:
            data = f.read()

        print(f"Pre-extracting {num_positions} positions...")
        features, targets = _extract_all(data, num_positions, eval_weight)
        self.features = torch.from_numpy(features)
        self.targets = torch.from_numpy(targets)
        print("Pre-extraction complete.")

    def __len__(self):
        return len(self.targets)

    def __getitem__(self, idx):
        return self.features[idx], self.targets[idx]


def train(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    num_cores = os.cpu_count()
    print(f"Using device: {device}, threads: {num_cores}")

    dataset = SelfPlayDataset(args.data, eval_weight=args.eval_weight)
    num_positions = len(dataset)
    print(f"Loaded {num_positions} positions from {args.data}")

    # Split into train/val
    val_size = max(1, int(len(dataset) * _trn["training"]["val_split"]))
    train_size = len(dataset) - val_size
    train_set, val_set = random_split(
        dataset,
        [train_size, val_size],
        generator=torch.Generator().manual_seed(_trn["training"]["random_seed"]),
    )

    use_cuda = device.type == "cuda"
    train_loader = DataLoader(
        train_set,
        batch_size=args.batch_size,
        shuffle=True,
        pin_memory=use_cuda,
    )
    val_loader = DataLoader(
        val_set,
        batch_size=args.batch_size,
        shuffle=False,
        pin_memory=use_cuda,
    )

    model = NNUE().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
    scaler = torch.amp.GradScaler(enabled=use_cuda)

    best_val_loss = float("inf")
    patience_counter = 0
    best_state = None
    epoch_log = []

    for epoch in range(args.epochs):
        # Training
        model.train()
        train_loss = 0.0
        for features, targets in train_loader:
            features, targets = features.to(device), targets.to(device)

            with torch.amp.autocast(device_type=device.type, enabled=use_cuda):
                output = model(features)
                loss = F.mse_loss(output, targets)

            optimizer.zero_grad()
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            train_loss += loss.item() * features.size(0)

        train_loss /= train_size

        # Validation
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for features, targets in val_loader:
                features, targets = features.to(device), targets.to(device)
                with torch.amp.autocast(device_type=device.type, enabled=use_cuda):
                    output = model(features)
                    loss = F.mse_loss(output, targets)
                val_loss += loss.item() * features.size(0)

        val_loss /= val_size

        improved = val_loss < best_val_loss
        epoch_log.append((epoch + 1, train_loss, val_loss, improved))

        print(
            f"Epoch {epoch + 1}/{args.epochs} - "
            f"train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}"
        )

        # Early stopping
        if improved:
            best_val_loss = val_loss
            patience_counter = 0
            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}
            if args.output:
                torch.save(best_state, args.output)
                print(f"  Saved best model to {args.output}")
        else:
            patience_counter += 1
            if patience_counter >= args.patience:
                print(f"Early stopping at epoch {epoch + 1}")
                break

    print(f"Training complete. Best val loss: {best_val_loss:.4f}")
    if args.output:
        print(f"Model saved to {args.output}")

    if getattr(args, "log", None):
        _write_log(args, num_positions, epoch_log, best_val_loss)

    return best_state


def _write_log(args, num_positions, epoch_log, best_val_loss):
    log_path = Path(args.log)
    log_path.parent.mkdir(parents=True, exist_ok=True)
    lines = [
        "# Training Log",
        "",
        f"- **Positions**: {num_positions:,}",
        f"- **Batch size**: {args.batch_size}",
        f"- **Learning rate**: {args.lr}",
        f"- **Eval weight**: {args.eval_weight}",
        f"- **Best val loss**: {best_val_loss:.6f}",
        f"- **Epochs run**: {len(epoch_log)}/{args.epochs}",
        "",
        "| Epoch | Train Loss | Val Loss | Best |",
        "|------:|-----------:|---------:|:----:|",
    ]
    for epoch, tl, vl, improved in epoch_log:
        marker = "*" if improved else ""
        lines.append(f"| {epoch} | {tl:.6f} | {vl:.6f} | {marker} |")
    lines.append("")
    log_path.write_text("\n".join(lines))
    print(f"Training log written to {log_path}")


def main():
    parser = argparse.ArgumentParser(description="Train NNUE from self-play data")
    parser.add_argument(
        "--data", required=True, help="Path to binary training data (.bin)"
    )
    parser.add_argument(
        "--output", default="nnue_weights.pt", help="Output PyTorch model path"
    )
    parser.add_argument("--epochs", type=int, default=_trn["training"]["epochs"])
    parser.add_argument(
        "--batch-size", type=int, default=_trn["training"]["batch_size"]
    )
    parser.add_argument("--lr", type=float, default=_trn["training"]["lr"])
    parser.add_argument("--patience", type=int, default=_trn["training"]["patience"])
    parser.add_argument(
        "--eval-weight",
        type=float,
        default=_trn["training"]["eval_weight"],
        help="Weight for search eval vs game result in target (0-1)",
    )
    parser.add_argument(
        "--log",
        help="Path to write training log as markdown (.md)",
    )
    args = parser.parse_args()

    train(args)


if __name__ == "__main__":
    main()
